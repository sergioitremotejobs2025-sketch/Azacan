# Kubernetes Implementation Guide: Libro-Mind

This guide details how to deploy the **Libro-Mind** full-stack application (Django + Next.js + PostgreSQL/pgvector + Ollama) onto a Kubernetes cluster.

---

## 1. Architecture Overview
In a Kubernetes environment, our Docker Compose setup is translated into the following components:

- **Namespace**: `libro-mind` (recommended)
- **Database**: PostgreSQL StateFulSet with `pgvector`.
- **Backend**: Django Deployment (Stateless).
- **Frontend**: Next.js Deployment (Stateless).
- **AI Service**: Ollama Deployment (with optional GPU support).
- **External Mock**: JSON Server Deployment.

---

## 2. Prerequisites
- A Kubernetes cluster (Minikube, GKE, EKS, or k3s).
- `kubectl` configured.
- A Container Registry (Docker Hub, GHCR, GCR).
- **Helm** (optional but recommended for DB management).

---

## 3. Implementation Steps

### 3.1 Docker Images
You must build and push your images to a registry before deploying.

```bash
# Backend
docker build -t your-registry/libro-mind-backend:latest -f docker-compose-app/backend.Dockerfile .
docker push your-registry/libro-mind-backend:latest

# Frontend
docker build -t your-registry/libro-mind-frontend:latest -f docker-compose-app/frontend.Dockerfile .
docker push your-registry/libro-mind-frontend:latest
```

### 3.2 Configuration (Secrets & ConfigMaps)
Create a `secrets.yaml` and `configmap.yaml` to manage environment variables.

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: libro-mind-secrets
type: Opaque
data:
  POSTGRES_PASSWORD: <base64-encoded-password>
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: libro-mind-config
data:
  POSTGRES_DB: "postgres"
  POSTGRES_USER: "postgres"
  POSTGRES_HOST: "postgres-service"
  OLLAMA_BASE_URL: "http://ollama-service:11434"
```

### 3.3 Database (PostgreSQL + pgvector)
We use a **StatefulSet** to ensure data persistence.

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: "postgres-service"
  replicas: 1
  template:
    spec:
      containers:
      - name: postgres
        image: pgvector/pgvector:pg15
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: pgdata
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: pgdata
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
```

### 3.4 AI Service (Ollama)
Deploying Ollama requires balancing CPU vs GPU.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
spec:
  template:
    spec:
      containers:
      - name: ollama
        image: ollama/ollama:latest
        ports:
        - containerPort: 11434
        resources:
          limits:
            nvidia.com/gpu: 1 # Add if your nodes have GPUs
```
*Note: You must run a `PostStart` hook or a separate Job to pull the model:*
`ollama pull deepseek-r1:1.5b`

---

## 4. Deployment Workflow

### 1. Networking (Services & Ingress)
- Create `ClusterIP` services for internal communication (Backend, DB, Ollama).
- Create a `LoadBalancer` or `Ingress` for the Frontend.

### 2. Data Initialization
To import the `book_store_db_backup.sql` into Kubernetes:
1. Create a `ConfigMap` from the SQL file (if < 1MB) OR
2. Use `kubectl cp` to move the file into the Postgres pod.
3. Exec into the pod:
   ```bash
   kubectl exec -it postgres-0 -- psql -U postgres -d postgres -f /path/to/backup.sql
   ```

### 3. Horizontal Scaling
Unlike Docker Compose, you can scale the Backend and Frontend pods independently based on traffic:
```bash
kubectl scale deployment libro-mind-backend --replicas=3
```

---

## 5. Critical Considerations for K8s

1. **Volume Persistence**: In Docker Compose, we used local paths. In K8s, use `PersistentVolumeClaims (PVC)` to ensure your database and media files survive pod restarts.
2. **Media Storage**: If users upload book covers, use a shared storage (like AWS S3 or GCP Cloud Storage) or a `Shared PVC` (ReadWriteMany), as individual pod disks are ephemeral.
3. **Health Checks**: 
   - Backend: `/api/recommend/query/` (check if 200).
   - Frontend: `/` (check if 200).
4. **Proxy Handling**: Ensure the Next.js API route points to the backend ClusterIP service name (e.g., `http://backend-service:8000`).

---
*Generated by Antigravity AI - February 2026*
